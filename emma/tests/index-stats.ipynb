{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install pandas matplotlib\n",
    "\n",
    "import ast\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T19:11:06.744792Z",
     "start_time": "2024-05-16T19:11:04.988032Z"
    }
   },
   "id": "32a1457c05a87883",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/nikola/Projects/emma/venv/lib/python3.9/site-packages (2.2.2)\r\n",
      "Requirement already satisfied: matplotlib in /Users/nikola/Projects/emma/venv/lib/python3.9/site-packages (3.9.0)\r\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/nikola/Projects/emma/venv/lib/python3.9/site-packages (from pandas) (1.26.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/nikola/Projects/emma/venv/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/nikola/Projects/emma/venv/lib/python3.9/site-packages (from pandas) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/nikola/Projects/emma/venv/lib/python3.9/site-packages (from pandas) (2024.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/nikola/Projects/emma/venv/lib/python3.9/site-packages (from matplotlib) (1.2.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/nikola/Projects/emma/venv/lib/python3.9/site-packages (from matplotlib) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/nikola/Projects/emma/venv/lib/python3.9/site-packages (from matplotlib) (4.51.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/nikola/Projects/emma/venv/lib/python3.9/site-packages (from matplotlib) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/nikola/Projects/emma/venv/lib/python3.9/site-packages (from matplotlib) (24.0)\r\n",
      "Requirement already satisfied: pillow>=8 in /Users/nikola/Projects/emma/venv/lib/python3.9/site-packages (from matplotlib) (10.3.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/nikola/Projects/emma/venv/lib/python3.9/site-packages (from matplotlib) (3.1.2)\r\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/nikola/Projects/emma/venv/lib/python3.9/site-packages (from matplotlib) (6.4.0)\r\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/nikola/Projects/emma/venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.18.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/nikola/Projects/emma/venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.0\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-05-16T19:11:06.907553Z",
     "start_time": "2024-05-16T19:11:06.746370Z"
    }
   },
   "source": [
    "dtype_spec = {\n",
    "    'sent': int,\n",
    "    'words': int,\n",
    "    'tok_b': int,\n",
    "    'tok_d': int,\n",
    "    'tok_x': int,\n",
    "    'tok_s': int,\n",
    "    'chrs': int\n",
    "}\n",
    "\n",
    "df = pd.read_csv('../../data/mulabel/raw/stats-short.csv', dtype=dtype_spec, on_bad_lines='warn')\n",
    "#df['labels'] = df['labels'].apply(ast.literal_eval)\n",
    "\n",
    "print(f'Number of samples: {df.shape[0]}')\n",
    "print(f'And columns: {df.columns}')"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'sent'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[0;32mparsers.pyx:1161\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: Cannot cast array data from dtype('O') to dtype('int64') according to the rule 'safe'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 11\u001B[0m\n\u001B[1;32m      1\u001B[0m dtype_spec \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msent\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28mint\u001B[39m,\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwords\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28mint\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchrs\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28mint\u001B[39m\n\u001B[1;32m      9\u001B[0m }\n\u001B[0;32m---> 11\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m../../data/mulabel/raw/stats-short.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype_spec\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mon_bad_lines\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mwarn\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m#df['labels'] = df['labels'].apply(ast.literal_eval)\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNumber of samples: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdf\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Projects/emma/venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m   1013\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m   1014\u001B[0m     dialect,\n\u001B[1;32m   1015\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1022\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m   1023\u001B[0m )\n\u001B[1;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/emma/venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:626\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n\u001B[1;32m    625\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m parser:\n\u001B[0;32m--> 626\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mparser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/emma/venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1923\u001B[0m, in \u001B[0;36mTextFileReader.read\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m   1916\u001B[0m nrows \u001B[38;5;241m=\u001B[39m validate_integer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnrows\u001B[39m\u001B[38;5;124m\"\u001B[39m, nrows)\n\u001B[1;32m   1917\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1918\u001B[0m     \u001B[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001B[39;00m\n\u001B[1;32m   1919\u001B[0m     (\n\u001B[1;32m   1920\u001B[0m         index,\n\u001B[1;32m   1921\u001B[0m         columns,\n\u001B[1;32m   1922\u001B[0m         col_dict,\n\u001B[0;32m-> 1923\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[attr-defined]\u001B[39;49;00m\n\u001B[1;32m   1924\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnrows\u001B[49m\n\u001B[1;32m   1925\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1926\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m   1927\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/Projects/emma/venv/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001B[0m, in \u001B[0;36mCParserWrapper.read\u001B[0;34m(self, nrows)\u001B[0m\n\u001B[1;32m    232\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlow_memory:\n\u001B[0;32m--> 234\u001B[0m         chunks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_low_memory\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    235\u001B[0m         \u001B[38;5;66;03m# destructive to chunks\u001B[39;00m\n\u001B[1;32m    236\u001B[0m         data \u001B[38;5;241m=\u001B[39m _concatenate_chunks(chunks)\n",
      "File \u001B[0;32mparsers.pyx:838\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mparsers.pyx:921\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._read_rows\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mparsers.pyx:1066\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mparsers.pyx:1167\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: invalid literal for int() with base 10: 'sent'"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "9fc86a26b6391914",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Compute text length distributions"
   ]
  },
  {
   "cell_type": "code",
   "id": "75a4cc195895788f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "char_bins = [i for i in range(0, 20001, 1000)]\n",
    "char_bins.append(float('inf'))\n",
    "char_histogram_counts = pd.cut(df['chrs'], bins=char_bins).value_counts().sort_index()\n",
    "char_histogram_percentages = (char_histogram_counts / df.shape[0]) * 100\n",
    "\n",
    "word_bins = [i for i in range(0, 2001, 100)]\n",
    "word_bins.append(float('inf'))\n",
    "word_histogram_counts = pd.cut(df['tok_w'], bins=word_bins).value_counts().sort_index()\n",
    "word_histogram_percentages = (word_histogram_counts / df.shape[0]) * 100\n",
    "\n",
    "sent_bins = [i for i in range(0, 201, 10)]\n",
    "sent_bins.append(float('inf'))\n",
    "sent_histogram_counts = pd.cut(df['sent'], bins=sent_bins).value_counts().sort_index()\n",
    "sent_histogram_percentages = (sent_histogram_counts / df.shape[0]) * 100\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 5))  # 1 row, 2 columns\n",
    "char_histogram_percentages.plot(\n",
    "    ax=axs[0], kind='bar',\n",
    "    title='Histogram of Character Counts in Text Samples', \n",
    "    xlabel='Character Count Intervals',\n",
    "    ylabel='Percentage of Samples'\n",
    ")\n",
    "axs[0].set_xticklabels(char_bins[1:])\n",
    "word_histogram_percentages.plot(\n",
    "    ax=axs[1], kind='bar', \n",
    "    title='Histogram of Word Token Counts in Text Samples', \n",
    "    xlabel='Word Token Count Intervals',\n",
    "    ylabel='Percentage of Samples'\n",
    ")\n",
    "axs[1].set_xticklabels(word_bins[1:])\n",
    "sent_histogram_percentages.plot(\n",
    "    ax=axs[2], kind='bar', \n",
    "    title='Histogram of Sentence Counts in Text Samples', \n",
    "    xlabel='Sentence Count Intervals',\n",
    "    ylabel='Percentage of Samples'\n",
    ")\n",
    "axs[2].set_xticklabels(sent_bins[1:])\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "10e5ccf915cabc03",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Compute distribution by language"
   ]
  },
  {
   "cell_type": "code",
   "id": "3992b135a31e7595",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "language_counts = df['language'].value_counts()\n",
    "filtered_language_counts = language_counts[language_counts > 100]\n",
    "filtered_language_counts.plot(kind='bar')\n",
    "plt.xlabel('Languages')\n",
    "plt.ylabel('Number of samples')\n",
    "plt.title('Number of samples for each language')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Distributions over the type of source (Media Type)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3b964766517f1c8"
  },
  {
   "cell_type": "code",
   "source": [
    "industries = df['type'].explode()\n",
    "industries.value_counts().plot(kind='bar')\n",
    "plt.xlabel('Media Types')\n",
    "plt.ylabel('Number of samples')\n",
    "plt.title('Number of samples for each Media Type')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c93167133cc614d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "988327d64f521273",
   "metadata": {
    "collapsed": false
   },
   "source": "Compute average characters, words and sentences per sub-word token for each language. (XLM-R and Deberta tokenizers)"
  },
  {
   "cell_type": "code",
   "id": "9117c3255d1aa48b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "df['char_xlmr_ratio'] = df['chrs'] / df['tok_x']\n",
    "df['word_xlmr_ratio'] = df['words'] / df['tok_x']\n",
    "df['sent_xlmr_ratio'] = df['sent'] / df['tok_x']\n",
    "df['char_deb_ratio'] = df['chrs'] / df['tok_d']\n",
    "df['word_deb_ratio'] = df['words'] / df['tok_d']\n",
    "df['sent_deb_ratio'] = df['sent'] / df['tok_d']\n",
    "\n",
    "language_statistics = df.groupby('language').agg(\n",
    "    avg_chrs_cl100k=pd.NamedAgg(column='char_xlmr_ratio', aggfunc='mean'),\n",
    "    avg_words_cl100k=pd.NamedAgg(column='word_xlmr_ratio', aggfunc='mean'),\n",
    "    avg_sents_cl100k=pd.NamedAgg(column='sent_xlmr_ratio', aggfunc='mean'),\n",
    "    avg_chrs_sp=pd.NamedAgg(column='char_deb_ratio', aggfunc='mean'),\n",
    "    avg_words_sp=pd.NamedAgg(column='word_deb_ratio', aggfunc='mean'),\n",
    "    avg_sents_sp=pd.NamedAgg(column='sent_deb_ratio', aggfunc='mean'),\n",
    "    count=pd.NamedAgg(column='characters', aggfunc='count')\n",
    ")\n",
    "\n",
    "filtered_language_statistics = language_statistics[language_statistics['count'] > 1000].sort_values(by=['count'], ascending=[False])\n",
    "display(filtered_language_statistics)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
