{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install pandas matplotlib\n",
    "\n",
    "import ast\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T12:51:46.037645Z",
     "start_time": "2024-05-16T12:51:42.160594Z"
    }
   },
   "id": "32a1457c05a87883",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/nikola/projects/emma/.venv/lib/python3.11/site-packages (2.2.0)\r\n",
      "Requirement already satisfied: matplotlib in /home/nikola/projects/emma/.venv/lib/python3.11/site-packages (3.8.2)\r\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /home/nikola/projects/emma/.venv/lib/python3.11/site-packages (from pandas) (1.26.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/nikola/projects/emma/.venv/lib/python3.11/site-packages (from pandas) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/nikola/projects/emma/.venv/lib/python3.11/site-packages (from pandas) (2023.4)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/nikola/projects/emma/.venv/lib/python3.11/site-packages (from pandas) (2023.4)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/nikola/projects/emma/.venv/lib/python3.11/site-packages (from matplotlib) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /home/nikola/projects/emma/.venv/lib/python3.11/site-packages (from matplotlib) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/nikola/projects/emma/.venv/lib/python3.11/site-packages (from matplotlib) (4.47.2)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/nikola/projects/emma/.venv/lib/python3.11/site-packages (from matplotlib) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/nikola/projects/emma/.venv/lib/python3.11/site-packages (from matplotlib) (23.2)\r\n",
      "Requirement already satisfied: pillow>=8 in /home/nikola/projects/emma/.venv/lib/python3.11/site-packages (from matplotlib) (10.2.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/nikola/projects/emma/.venv/lib/python3.11/site-packages (from matplotlib) (3.1.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/nikola/projects/emma/.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2361859/1983271606.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-05-16T12:51:46.597484Z",
     "start_time": "2024-05-16T12:51:46.041381Z"
    }
   },
   "source": [
    "df = pd.read_csv('EMMA_1mio-v1.0-index.csv')\n",
    "df['industries'] = df['industries'].apply(ast.literal_eval)\n",
    "\n",
    "print(f'Number of samples: {df.shape[0]}')\n",
    "print(f'And columns: {df.columns}')"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'EMMA_1mio-v1.0-index.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mEMMA_1mio-v1.0-index.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mindustries\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mindustries\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(ast\u001B[38;5;241m.\u001B[39mliteral_eval)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNumber of samples: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdf\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/projects/emma/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1024\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m   1011\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m   1012\u001B[0m     dialect,\n\u001B[1;32m   1013\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1020\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m   1021\u001B[0m )\n\u001B[1;32m   1022\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m-> 1024\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/emma/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:618\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    615\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    617\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 618\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    620\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    621\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m~/projects/emma/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1618\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m   1615\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1617\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1618\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/emma/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1878\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1876\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[1;32m   1877\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1878\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1879\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1880\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1881\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1882\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1883\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1884\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1885\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1886\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1887\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1888\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1889\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m~/projects/emma/.venv/lib/python3.11/site-packages/pandas/io/common.py:873\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    868\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    869\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    870\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    871\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    872\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 873\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    874\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    875\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    876\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    877\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    878\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    879\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    880\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    881\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    882\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'EMMA_1mio-v1.0-index.csv'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "9fc86a26b6391914",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Compute text length distributions"
   ]
  },
  {
   "cell_type": "code",
   "id": "75a4cc195895788f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "char_bins = [i for i in range(0, 20001, 1000)]\n",
    "char_bins.append(float('inf'))\n",
    "char_histogram_counts = pd.cut(df['characters'], bins=char_bins).value_counts().sort_index()\n",
    "char_histogram_percentages = (char_histogram_counts / df.shape[0]) * 100\n",
    "\n",
    "word_bins = [i for i in range(0, 2001, 100)]\n",
    "word_bins.append(float('inf'))\n",
    "word_histogram_counts = pd.cut(df['word_tok'], bins=word_bins).value_counts().sort_index()\n",
    "word_histogram_percentages = (word_histogram_counts / df.shape[0]) * 100\n",
    "\n",
    "sent_bins = [i for i in range(0, 201, 10)]\n",
    "sent_bins.append(float('inf'))\n",
    "sent_histogram_counts = pd.cut(df['sentences'], bins=sent_bins).value_counts().sort_index()\n",
    "sent_histogram_percentages = (sent_histogram_counts / df.shape[0]) * 100\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 5))  # 1 row, 2 columns\n",
    "char_histogram_percentages.plot(\n",
    "    ax=axs[0], kind='bar',\n",
    "    title='Histogram of Character Counts in Text Samples', \n",
    "    xlabel='Character Count Intervals',\n",
    "    ylabel='Percentage of Samples'\n",
    ")\n",
    "axs[0].set_xticklabels(char_bins[1:])\n",
    "word_histogram_percentages.plot(\n",
    "    ax=axs[1], kind='bar', \n",
    "    title='Histogram of Word Token Counts in Text Samples', \n",
    "    xlabel='Word Token Count Intervals',\n",
    "    ylabel='Percentage of Samples'\n",
    ")\n",
    "axs[1].set_xticklabels(word_bins[1:])\n",
    "sent_histogram_percentages.plot(\n",
    "    ax=axs[2], kind='bar', \n",
    "    title='Histogram of Sentence Counts in Text Samples', \n",
    "    xlabel='Sentence Count Intervals',\n",
    "    ylabel='Percentage of Samples'\n",
    ")\n",
    "axs[2].set_xticklabels(sent_bins[1:])\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "10e5ccf915cabc03",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Compute distribution by language"
   ]
  },
  {
   "cell_type": "code",
   "id": "3992b135a31e7595",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "language_counts = df['language'].value_counts()\n",
    "filtered_language_counts = language_counts[language_counts > 100]\n",
    "filtered_language_counts.plot(kind='bar')\n",
    "plt.xlabel('Languages')\n",
    "plt.ylabel('Number of samples')\n",
    "plt.title('Number of samples for each language')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Distributions over the type of source (Media Type)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3b964766517f1c8"
  },
  {
   "cell_type": "code",
   "source": [
    "industries = df['media_type'].explode()\n",
    "industries.value_counts().plot(kind='bar')\n",
    "plt.xlabel('Media Types')\n",
    "plt.ylabel('Number of samples')\n",
    "plt.title('Number of samples for each Media Type')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c93167133cc614d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "And distributions over Industries / Domains"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af97e48ffb1e53c1"
  },
  {
   "cell_type": "code",
   "source": [
    "industries = df['industries'].explode()\n",
    "industries.value_counts().plot(kind='bar')\n",
    "plt.xlabel('Industries')\n",
    "plt.ylabel('Number of samples')\n",
    "plt.title('Number of samples for each industry')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c30e5996db76116d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "988327d64f521273",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Compute average characters, words and sentences per sub-word token for each language. (cl100k_base and SentencePiece encodings)"
   ]
  },
  {
   "cell_type": "code",
   "id": "9117c3255d1aa48b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "df['char_cl100k_ratio'] = df['characters'] / df['cl100k_tok']\n",
    "df['word_cl100k_ratio'] = df['word_tok'] / df['cl100k_tok']\n",
    "df['sent_cl100k_ratio'] = df['sentences'] / df['cl100k_tok']\n",
    "df['char_sp_ratio'] = df['characters'] / df['sp_tok']\n",
    "df['word_sp_ratio'] = df['word_tok'] / df['sp_tok']\n",
    "df['sent_sp_ratio'] = df['sentences'] / df['sp_tok']\n",
    "\n",
    "language_statistics = df.groupby('language').agg(\n",
    "    avg_chrs_cl100k=pd.NamedAgg(column='char_cl100k_ratio', aggfunc='mean'),\n",
    "    avg_words_cl100k=pd.NamedAgg(column='word_cl100k_ratio', aggfunc='mean'),\n",
    "    avg_sents_cl100k=pd.NamedAgg(column='sent_cl100k_ratio', aggfunc='mean'),\n",
    "    avg_chrs_sp=pd.NamedAgg(column='char_sp_ratio', aggfunc='mean'),\n",
    "    avg_words_sp=pd.NamedAgg(column='word_sp_ratio', aggfunc='mean'),\n",
    "    avg_sents_sp=pd.NamedAgg(column='sent_sp_ratio', aggfunc='mean'),\n",
    "    count=pd.NamedAgg(column='characters', aggfunc='count')\n",
    ")\n",
    "\n",
    "filtered_language_statistics = language_statistics[language_statistics['count'] > 1000].sort_values(by=['count'], ascending=[False])\n",
    "display(filtered_language_statistics)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
